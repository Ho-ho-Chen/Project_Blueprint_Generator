import google.generativeai as genai
import re
import time
import streamlit as st

def configure_genai(api_key):
    """è¨­å®š Gemini API"""
    genai.configure(api_key=api_key)

def generate_blueprint(product_idea):
    """
    å‘¼å« AI ç”Ÿæˆå››ä»½æ¨™æº–åŒ–æ–‡ä»¶
    å…·å‚™è‡ªå‹•é™ç´šæ©Ÿåˆ¶ï¼šå˜—è©¦å¤šç¨®æ¨¡å‹ç‰ˆæœ¬ï¼Œç›´åˆ°æˆåŠŸç‚ºæ­¢ã€‚
    """
    
    # å®šç¾©æ¨¡å‹å„ªå…ˆé †åºæ¸…å–® (ç”±æ–°åˆ°èˆŠï¼Œç”±å¿«åˆ°æ…¢)
    # ç­–ç•¥ï¼š
    # 1. 2.0 Flash Exp: æœ€æ–°ã€æœ€å¼· (ä½†ä¹Ÿæœ€å®¹æ˜“é¡åº¦æ»¿)
    # 2. 1.5 Flash: é€Ÿåº¦å¿«ã€ç©©å®š
    # 3. 1.5 Pro: æ¯”è¼ƒè°æ˜ï¼Œä½†æ¯”è¼ƒæ…¢
    # 4. gemini-pro: 1.0 ç‰ˆæœ¬ï¼Œæœ€èˆŠä½†é€šå¸¸çµ•å°èƒ½ç”¨ (ä¿åº•)
    model_priority = [
        'gemini-2.0-flash-exp',
        'gemini-1.5-flash',
        'gemini-1.5-flash-latest',
        'gemini-1.5-pro',
        'gemini-pro'
    ]
    
    last_error = ""

    # åœ¨ä»‹é¢ä¸Šé¡¯ç¤ºæˆ‘å€‘æ­£åœ¨åšä»€éº¼
    status_placeholder = st.empty()

    for target_model in model_priority:
        try:
            status_placeholder.caption(f"ğŸ”„ æ­£åœ¨å˜—è©¦é€£ç·šæ¨¡å‹ï¼š{target_model} ...")
            
            # å»ºç«‹æ¨¡å‹å¯¦ä¾‹
            model = genai.GenerativeModel(target_model)
            
            prompt = f"""
            ä½ æ˜¯ä¸€ä½èè‹±è»Ÿé«”æ¶æ§‹å¸«ã€‚è«‹æ ¹æ“šä½¿ç”¨è€…çš„ç”¢å“é»å­ï¼Œç”Ÿæˆä¸€å€‹å®Œæ•´çš„è»Ÿé«”å°ˆæ¡ˆæ–‡ä»¶åŒ…ã€‚
            ä½ éœ€è¦ç”Ÿæˆä»¥ä¸‹å››å€‹æª”æ¡ˆçš„å…§å®¹ï¼Œä¸¦ç”¨ç‰¹å®šçš„åˆ†éš”ç·šéš”é–‹ã€‚
            
            ã€ç”¢å“é»å­ã€‘ï¼š
            {product_idea}

            ã€è«‹åš´æ ¼ä¾ç…§ä»¥ä¸‹æ ¼å¼è¼¸å‡ºï¼Œä¸è¦åŒ…å«å…¶ä»–é–‹å ´ç™½ã€‘ï¼š

            ====FILE: README.md====
            (åœ¨æ­¤æ’°å¯« README.md çš„å…§å®¹ï¼šå°ˆæ¡ˆæ¨™é¡Œã€æè¿°ã€å®‰è£æŒ‡å—ã€æŠ€è¡“æ£§æ¸…å–®)

            ====FILE: SPEC.md====
            (åœ¨æ­¤æ’°å¯« SPEC.md çš„å…§å®¹ï¼šè©³ç´°è¦æ ¼ã€API ç«¯é»å®šç¾©ã€‚è«‹åŒ…å«è‡³å°‘ä¸€å€‹ Mermaid æ ¼å¼çš„ç³»çµ±æ¶æ§‹åœ–æˆ–æ˜¯æµç¨‹åœ–)

            ====FILE: REPORT.md====
            (åœ¨æ­¤æ’°å¯« REPORT.md çš„å…§å®¹ï¼šé–‹ç™¼è©•ä¼°å ±å‘Šã€é æœŸé‡åˆ°çš„æŠ€è¡“é›£é»ã€è§£æ±ºæ–¹æ¡ˆåˆ†æ)

            ====FILE: TODOLIST.md====
            (åœ¨æ­¤æ’°å¯« TODOLIST.md çš„å…§å®¹ï¼šæ¢åˆ—å¼é–‹ç™¼ä»»å‹™æ¸…å–®ï¼ŒåŒ…å« Checkbox - [ ])
            """
            
            # ç™¼é€è«‹æ±‚
            response = model.generate_content(prompt)
            text = response.text
            
            # --- è§£æ AI å›å‚³çš„æ–‡å­— ---
            files = {}
            patterns = {
                "README.md": r"====FILE: README\.md====\n(.*?)(?====FILE:|$)",
                "SPEC.md": r"====FILE: SPEC\.md====\n(.*?)(?====FILE:|$)",
                "REPORT.md": r"====FILE: REPORT\.md====\n(.*?)(?====FILE:|$)",
                "TODOLIST.md": r"====FILE: TODOLIST\.md====\n(.*?)(?====FILE:|$)",
            }
            
            for filename, pattern in patterns.items():
                match = re.search(pattern, text, re.DOTALL)
                if match:
                    files[filename] = match.group(1).strip()
                else:
                    files[filename] = f"âš ï¸ ({target_model}) ç”Ÿæˆå…§å®¹éºå¤±ï¼Œè«‹é‡è©¦ã€‚"

            # æˆåŠŸï¼
            status_placeholder.success(f"âœ… æˆåŠŸä½¿ç”¨æ¨¡å‹ï¼š{target_model} ç”Ÿæˆå®Œç•¢ï¼")
            time.sleep(1) # è®“ä½¿ç”¨è€…çœ‹åˆ°æˆåŠŸè¨Šæ¯
            status_placeholder.empty() # æ¸…é™¤è¨Šæ¯
            
            files["_model_used"] = target_model 
            return files

        except Exception as e:
            error_msg = str(e)
            last_error = error_msg
            print(f"âŒ æ¨¡å‹ {target_model} å¤±æ•—: {error_msg}")
            
            # åˆ¤æ–·æ˜¯å¦è¦ç¨å¾®ä¼‘æ¯ä¸€ä¸‹å†è©¦ä¸‹ä¸€å€‹ (é¿å…é€£çºŒè«‹æ±‚è¢«ç•¶ä½œæ”»æ“Š)
            if "429" in error_msg:
                status_placeholder.warning(f"âš ï¸ æ¨¡å‹ {target_model} é¡åº¦å·²æ»¿ï¼Œåˆ‡æ›ä¸‹ä¸€å€‹...")
                time.sleep(2)
            else:
                status_placeholder.warning(f"âš ï¸ æ¨¡å‹ {target_model} ç‰ˆæœ¬ä¸æ”¯æ´ï¼Œåˆ‡æ›ä¸‹ä¸€å€‹...")
            
            continue

    # å¦‚æœæ‰€æœ‰æ¨¡å‹éƒ½å¤±æ•—
    return {"error": f"âš ï¸ æ‰€æœ‰ AI æ¨¡å‹çš†ç„¡æ³•é€£ç·šã€‚\nå»ºè­°ï¼šè«‹åœ¨çµ‚ç«¯æ©ŸåŸ·è¡Œ `python -m pip install -U google-generativeai` æ›´æ–°å¥—ä»¶ã€‚\næœ€å¾ŒéŒ¯èª¤ï¼š{last_error}"}
